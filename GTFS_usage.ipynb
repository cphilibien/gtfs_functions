{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heures de pointe de la STM De 7h à 9h et de 16h à 18h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gtfs_functions.gtfs_functions import Feed\n",
    "\n",
    "folder_gtfs = 'GTFS_files/'\n",
    "\n",
    "# Definir les tranches horaires\n",
    "time_windows=[0, 5, 7, 9, 16, 18, 24]\n",
    "\n",
    "# Permet de selectionner le type de calendrier:\n",
    "#   - semaine (week)\n",
    "#   - fin de semaine (weekend) => Resultat errone car les data de samedi et dimanche sont additionnés \n",
    "#   - samedi (saturday)\n",
    "#   - dimanche (dimanche)\n",
    "#   - Aucun argument => tous les jours sont pris en compte \n",
    "#   mais le calcul de la frequence n'est pas juste car les horaires du samedi (par exemple) sont consideres comme un trajet en plus\n",
    "daysofweek = \"week\"\n",
    "\n",
    "# supprime certaines routes dans la liste (ici les lignes de métro)\n",
    "drop_routes = [\"1\", \"2\", \"4\", \"5\"]\n",
    "\n",
    "# supprime les cas de calendrier pour une journée afin d'eviter des double comptage (la suppresssion est la solution simple, a voir pour trouver mieux)\n",
    "drop_samedate = True\n",
    "\n",
    "# Ne prend pas en compte les trips associés a un calendar qui commence apres une date\n",
    "drop_service_after = \"20230619\"\n",
    "\n",
    "# Aggrege les routes qui se superpose (cas de la ligne 100 de la STM qui a 2 shapes)\n",
    "dissolve_routes = True\n",
    "#### TODO => Aggreger selon les linstring qui se croisent\n",
    "\n",
    "# aggrege les frequences par stop, pour toutes lignes qui passe a cet arret de bus (stop_freq_by_route doit etre à True)\n",
    "dissolve_stops = True\n",
    "\n",
    "# Permet de tagguer les routes associés au stop\n",
    "stop_freq_by_route= True\n",
    "\n",
    "feed = Feed(folder_gtfs+\"gtfs_stm.zip\", \n",
    "            time_windows=time_windows,\n",
    "            daysofweek=daysofweek, \n",
    "            busiest_date = False, \n",
    "            stop_freq_by_route= stop_freq_by_route,\n",
    "            drop_routes=drop_routes,\n",
    "            drop_samedate=drop_samedate,\n",
    "            drop_service_after= drop_service_after,\n",
    "            dissolve_route = dissolve_routes,\n",
    "            dissolve_stops = dissolve_stops)\n",
    "\n",
    "\n",
    "routes = feed.routes\n",
    "trips = feed.trips\n",
    "stops = feed.stops\n",
    "stop_times = feed.stop_times\n",
    "shapes = feed.shapes\n",
    "calendar = feed.calendar\n",
    "\n",
    "stops_freq = feed.stops_freq\n",
    "lines_freq = feed.lines_freq"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXPORTATION DES DONNÉES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_files_gpkg(df,name ):\n",
    "    gp = df.groupby('window')\n",
    "    folder = 'extract_files/frequencies/' + name\n",
    "    for g in gp.groups:\n",
    "        file_name = folder + '/' + name +'_frequencies_window_' + str(g) + '.gpkg'\n",
    "        print(file_name)\n",
    "        gp.get_group(g).to_file(file_name, driver=\"GPKG\")\n",
    "\n",
    "\n",
    "#### Extract STOPS FREQUENCIES\n",
    "extract_files_gpkg(stops_freq,'stops' )\n",
    "\n",
    "#### Extract LINES FREQUENCIES\n",
    "extract_files_gpkg(lines_freq,'lines' )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VALIDATION DES DONNÉES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(stops_freq.head(50))\n",
    "stops_freq.explore()\n",
    "stop_duplicated = stops_freq.loc[\n",
    "                stops_freq.duplicated(\n",
    "                    subset=[\"stop_id\", \"direction_id\", \"window\"], keep=False\n",
    "                ),\n",
    "                :,\n",
    "            ].sort_values(by=[\"stop_id\", \"direction_id\", \"window\"])\n",
    "display(stop_duplicated)\n",
    "# stop_duplicated.explore()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(lines_freq)\n",
    "lines_freq.explore()\n",
    "lines_duplicated = lines_freq.loc[\n",
    "                lines_freq.duplicated(\n",
    "                    subset=[\"route_id\", \"direction_id\", \"window\"], keep=False\n",
    "                ),\n",
    "                :,\n",
    "            ].sort_values(by=[\"route_id\", \"direction_id\", \"window\"])\n",
    "display(lines_duplicated)\n",
    "# lines_duplicated.explore()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
